# -*- coding: utf-8 -*-
"""Global terrorism.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ybWtvt2WcbXMEpAC9zLkSYAsdMz01ntc
"""

import numpy as np 
import pandas as pd 
import datetime as dt 
import matplotlib.pyplot as plt

from google.colab import drive
drive.mount('/content/drive')

cd /content/drive/MyDrive/Dataset

df = pd.read_csv("globalterrorismdb_0718dist.csv",encoding="latin1")

df = df[['iyear', 'imonth', 'iday', 'extended', 'country', 'provstate', 'country_txt', 'success', 'attacktype1_txt', 'targtype1_txt', 'gname',
         'weaptype1_txt']]
df.head()

start_year = 2000
country = 'United States'
df = df.loc[(df['iyear'] >= start_year) & (df['country_txt'] == country)]
df.head()

count = df['gname'].value_counts()
count.head(21)

num_names = 20
names = count.keys()[1:num_names+1]
names = list(names)
names

countries = pd.get_dummies(df['country_txt'])
countries.reset_index(drop = True, inplace = True)

states = pd.get_dummies(df['provstate'])
states.reset_index(drop = True, inplace = True)

attacks = pd.get_dummies(df['attacktype1_txt'])
attacks.reset_index(drop = True, inplace = True)

targets = pd.get_dummies(df['targtype1_txt'])
targets.reset_index(drop = True, inplace = True)

weapons = pd.get_dummies(df['weaptype1_txt'])
weapons.reset_index(drop = True, inplace = True)

df.reset_index(drop=True, inplace=True)
df_dummies = pd.concat([df, countries, states, attacks, targets, weapons], axis = 1)

df_dummies = df_dummies.drop(['country','imonth', 'iday', 'country_txt',
                              'provstate', 'attacktype1_txt','targtype1_txt',
                              'weaptype1_txt'],
                             axis = 1)
df_dummies.head()

unknown = df[df['gname'] == 'Unknown']
unknown.head()

df_dummies = df_dummies.loc[(df_dummies['gname'] != 'Unknown') & (df_dummies['gname'].isin(names))]
df_dummies.head()

x=df_dummies.loc[:,~df_dummies.columns.isin(['gname'])].values
y=df_dummies.loc[:,'gname'].values

from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test = train_test_split(x,y,test_size = 0.30, random_state = 0)

print(x_train.shape)
print(x_test.shape)
print(y_train.shape)
print(y_test.shape)

from sklearn.preprocessing import StandardScaler
ss = StandardScaler()

x_train_std = ss.fit_transform(x_train)
x_test_std = ss.transform(x_test)

from sklearn.cluster import KMeans
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import plot_confusion_matrix

import time
import warnings
warnings.filterwarnings('ignore')

"""# KNeighbors Classifier"""

knn = KNeighborsClassifier()

param_grid = {'n_neighbors':[5,10,15,25,30,50], 'weights': ['uniform','distance']}

grid_knn = GridSearchCV(knn,param_grid,scoring='accuracy',cv = 10,refit = True)

start_time = time.time()

grid_knn.fit(x_train_std,y_train)
print("Best Score ==> ", grid_knn.best_score_)
print("Tuned Paramerers ==> ", grid_knn.best_params_)
print("Accuracy on Train set ==> ", grid_knn.score(x_train_std,y_train))
print("Accuracy on Test set ==> ", grid_knn.score(x_test_std,y_test))

end_time = time.time()
run_time = end_time - start_time
print('Runtime of the Grid Search for the KNeighbors Algorithm: {:.5f}s'.format(run_time))

start_time = time.time()

knn = KNeighborsClassifier(**grid_knn.best_params_)
knn.fit(x_train_std, y_train)

print("Accuracy on Train set ==> ", knn.score(x_train_std,y_train))
print("Accuracy on Test set ==> ", knn.score(x_test_std,y_test))

end_time = time.time()
kn_run_time = end_time - start_time

print('Runtime of the KNeighbors Classifier Algorithm: {:.5f}s'.format(kn_run_time))

fig, ax = plt.subplots(figsize = (12,12))

matrix = plot_confusion_matrix(knn, x_test_std, y_test, ax=ax, xticks_rotation='vertical',
                               cmap='PuRd', normalize='true', values_format='.2f')
plt.title('KNeighbors Classifier Confusion Matrix')
plt.show()

knn_acc=print("Accuracy on Test set using KNeighbors: {:.4%}".format(knn.score(x_test_std,y_test)))
knn_rt=print('Runtime of the KNeighbors Classifier Algorithm: {:.4f}s'.format(kn_run_time))

"""# Decision Tree Classifier"""

from sklearn.tree import DecisionTreeClassifier
dtc = DecisionTreeClassifier()

param_grid = {'criterion':['gini','entropy'],'min_samples_leaf':[1, 2, 3, 4, 5, 10, 25, 50],'max_depth':np.arange(2, 10)}

grid_dtc = GridSearchCV(dtc,param_grid,scoring='accuracy',cv = 10,refit = True)

start_time = time.time()

grid_dtc.fit(x_train, y_train)
print("Best Score ==> ", grid_dtc.best_score_)
print("Tuned Paramerers ==> ", grid_dtc.best_params_)
print("Accuracy on Train set ==> ", grid_dtc.score(x_train,y_train))
print("Accuracy on Test set ==> ", grid_dtc.score(x_test,y_test))

end_time = time.time()
run_time = end_time - start_time
print('Runtime of the Grid Search for the Decision Tree Algorithm: {:.5f}s'.format(run_time))

start_time = time.time()

dtc = DecisionTreeClassifier(**grid_dtc.best_params_, random_state=42)
dtc.fit(x_train, y_train)

print("Accuracy on Train set ==> ", dtc.score(x_train,y_train))
print("Accuracy on Test set ==> ", dtc.score(x_test,y_test))

end_time = time.time()
dtc_run_time = end_time - start_time

print('Runtime of the Decision Tree Classifier Algorithm: {:.5f}s'.format(dtc_run_time))

features = df_dummies.loc[:,~df_dummies.columns.isin(['gname'])].columns
classes = df_dummies['gname'].unique()
classes.sort()

from sklearn import tree

fig, ax = plt.subplots(figsize = (28,16))
plt.tight_layout()
tree.plot_tree(dtc, ax=ax, feature_names=features, class_names = classes, 
               max_depth = 2, filled=True, fontsize=17, rounded=True);

fig, ax = plt.subplots(figsize = (12,12))

matrix = plot_confusion_matrix(dtc, x_test, y_test, ax=ax, xticks_rotation='vertical',
                               cmap='PuRd', normalize='true', values_format='.2f')
plt.title('Decision Tree Classifier Confusion Matrix')
plt.show()

dtc_acc=print("Accuracy on Test set using Decision Trees: {:.4%}".format(dtc.score(x_test,y_test)))
dtc_rt=print('Runtime of the Decision Tree Classifier Algorithm: {:.4f}s'.format(dtc_run_time))

"""# Naive Bayes"""

from sklearn.naive_bayes import GaussianNB

start_time = time.time()

nb = GaussianNB()
nb.fit(x_train, y_train)

print("Accuracy on Train set ==> ", nb.score(x_train,y_train))
print("Accuracy on Test set ==> ", nb.score(x_test,y_test))

end_time = time.time()
nb_run_time = end_time - start_time

print('Runtime of the Naive Bayes Algorithm: {:.5f}s'.format(nb_run_time))

fig, ax = plt.subplots(figsize = (12,12))

matrix = plot_confusion_matrix(nb, x_test, y_test, ax=ax, xticks_rotation='vertical', 
                               cmap='PuRd', normalize='true', values_format='.2f')
plt.title('Naive Bayes Confusion Matrix')
plt.show()

nb_acc=print("Accuracy on Test set using Naive Bayes: {:.4%}".format(nb.score(x_test,y_test)))
nb_rt=print('Runtime of the Naive Bayes Algorithm: {:.4f}s'.format(nb_run_time))

"""# Neural Network"""

from sklearn.neural_network import MLPClassifier

start_time = time.time()

mlp = MLPClassifier(hidden_layer_sizes=(40,40,40), max_iter=300, random_state=42)
mlp.fit(x_train_std, y_train)

print("Accuracy on Train set ==> ", mlp.score(x_train_std,y_train))
print("Accuracy on Test set ==> ", mlp.score(x_test_std,y_test))

end_time = time.time()
mlp_run_time = end_time - start_time

print('Runtime of the Neural Network: {:.5f}s'.format(mlp_run_time))

fig, ax = plt.subplots(figsize = (12,12))

matrix = plot_confusion_matrix(mlp, x_test_std, y_test, ax=ax, xticks_rotation='vertical',
                               cmap='PuRd', normalize='true', values_format='.2f')
plt.title('Neural Network Confusion Matrix')
plt.show()

nn_acc=print("Accuracy on Test set using Neural Network: {:.4%}".format(mlp.score(x_test_std,y_test)))
nn_rt=print('Runtime of the Neural Network: {:.4f}s'.format(mlp_run_time))

"""k-means"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd

from sklearn.cluster import KMeans
from sklearn.metrics.cluster import silhouette_score
from sklearn.preprocessing import scale, robust_scale

import matplotlib.pyplot as plt
import seaborn as sns
# %matplotlib inline

plt.rcParams['figure.figsize'] = (12, 8)
sns.set_palette('coolwarm')
sns.set_color_codes('bright')

data = pd.read_csv('terrorism_dataset.csv', encoding='latin1')

data = data[data['nkill'] <= 4].reset_index(drop=True)
data = data[data['nwound'] <= 7].reset_index(drop=True)

c = data.count().sort_values().drop([
    'eventid', 'country', 'iyear', 'natlty1', 'longitude', 'latitude', 'targsubtype1'])
_ = data[c[c > 100000].keys()].var().sort_values().plot.barh()

features = [
    'longitude',
    'latitude',
    
    'nwound',
    'nkill',
    
    'natlty1_txt',
    'targtype1_txt',
    'targsubtype1_txt',
    'weaptype1_txt',
    'attacktype1_txt',
]

X = pd.get_dummies(data[features])
X = X.T[X.var() > 0.05].T.fillna(0)
X = X.fillna(0)

print('Shape:', X.shape)
X.head()

scores = {}
for k in range(2, 11):
    print(k, end=', ')
    scores[k] = KMeans(n_clusters=k).fit(X).score(X)
_ = pd.Series(scores).plot.bar()

data['Cluster'] = KMeans(n_clusters=6).fit_predict(X) + 1
print('Silhouette Score:', silhouette_score(X, data['Cluster'], sample_size=10000) * 10000 // 1 / 100, '%')

names = data.groupby('Cluster')['region_txt'].describe()['top'].values
data['ClusterName'] = data['Cluster'].apply(lambda c: names[c - 1])

numerical = data.dtypes[data.dtypes != 'object'].keys()
exclude = [
    'eventid', 'Cluster', 'region', 'country', 'iyear', 
    'natlty1', 'natlty2', 'natlty3', 'imonth', 'iday',
    'guncertain1', 'guncertain2', 'guncertain3'
] + [col for col in numerical if 'type' in col or 'mode' in col or 'ransom' in col]
X_profiling = data[numerical.drop(exclude)].fillna(0)
X_profiling = pd.DataFrame(scale(X_profiling), columns=X_profiling.columns)
X_profiling['ClusterName'] = data['ClusterName']
_ = sns.heatmap(X_profiling.groupby('ClusterName').mean().drop(['longitude', 'latitude'], axis=1).T, 
               cmap='coolwarm')

ckeys = data['region_txt'].unique()
ckeys = dict(zip(ckeys, plt.cm.tab20(range(len(ckeys)))))

for i, x in pd.concat([X_profiling, data['region_txt']], axis=1).groupby('region_txt'):
    _ = plt.scatter(x['longitude'], x['latitude'], c=ckeys[i], marker='.', cmap='tab10', label=i)
_ = plt.legend(loc=3)

kmeans_acc=print('Accuracy of the model:', 
      len(data[data['region_txt'] == data['ClusterName']]) / len(data) * 10000 // 1 / 100, '%')

end_time = time.time()
scores_run_time = end_time - start_time

kmeans_rt=print('Runtime of the KMeans Algorithm: {:.5f}s'.format(scores_run_time))

"""XGBOOST"""

import pandas as pd
from sklearn.preprocessing import LabelEncoder
obj_df = (pd.read_csv('/content/preprocessed_data.csv')
        .replace({'?': 'unknown'}))  
obj_df.drop(obj_df.columns[obj_df.columns.str.contains('unnamed',case = False)],axis = 1, inplace = True)

from sklearn.model_selection import train_test_split
X = obj_df.drop(columns='provstate')
y = obj_df['provstate'].copy()
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42)

class MultiColumnLabelEncoder:
    
    def __init__(self, columns = None):
        self.columns = columns 
    def fit(self, X, y=None):
        return self
    def transform(self, X):
        '''
        Transforms columns of X specified in self.columns using
        LabelEncoder(). If no columns specified, transforms all
        columns in X.
        '''
        
        output = X.copy()
        
        if self.columns is not None:
            for col in self.columns:
                output[col] = LabelEncoder().fit_transform(output[col])
        else:
            for colname, col in output.iteritems():
                output[colname] = LabelEncoder().fit_transform(col)
        
        return output
    def fit_transform(self, X, y=None):
        return self.fit(X, y).transform(X)

le = MultiColumnLabelEncoder()
X_train_le = le.fit_transform(X_train)
X_train_le.head()

le = MultiColumnLabelEncoder()
X_test_le = le.fit_transform(X_test)
X_test_le.head()

X_train_le.dtypes

from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
y_train_le = le.fit_transform(y_train)
y_train_le

from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
y_test_le = le.fit_transform(y_test)
y_test_le

from xgboost import XGBClassifier
classifier = XGBClassifier()
classifier.fit(X_train_le, y_train_le)

from sklearn.metrics import confusion_matrix, accuracy_score
y_pred = classifier.predict(X_test_le)

from sklearn.model_selection import cross_val_score
accuracies = cross_val_score(estimator = classifier, X = X_train_le, y = y_train_le, cv = 10)
xgb_acc=print("Accuracy: {:.2f} %".format(accuracies.mean()*100))
print("Standard Deviation: {:.2f} %".format(accuracies.std()*100))

end_time = time.time()
classifier_run_time = end_time - start_time

xgb_rt=print('Runtime of the XGBoost Algorithm: {:.5f}s'.format(classifier_run_time))